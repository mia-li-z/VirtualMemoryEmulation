
No matter what customized page replacement algorithm you are implementing, you need to write details(how the customized algorithm determines which page to replace, what additional implementations you have added to the original code, etc.) of it in your final writeup or README.

# Experiments purposes and set up

1. Experiments purpose

    The goal of this experiment is to compare three page replacement algos with regard to the volume of disk writes and page faults that occur when running programs with various patterns of memory access. 

    By contrasting the outcomes of the three page replacement algorithms applied to different memory access patterns, we can learn which one is more appropriate for a given use case. 


2. Experimental setup
   * We ran our experiment on a Ubuntu machine with pandas 1.5.2 installed. 
   * Check pandas version:
	    > pip show pandas
   * If need to upgrade panda, please run the following command:
	    >pip install --upgrade pandas




The goal of this experiment is to compare three page replacement algos with regard to the volume of disk writes and page faults that occur when running programs with various patterns of memory access. 

By contrasting the outcomes of the three page replacement algorithms applied to different memory access patterns, we can learn which one is more appropriate for a given use case. 

We ran our experiment on a Ubuntu machine with pandas 1.5.2 installed. 
Check pandas version:
	>pip show pandas
If need to upgrade panda, please run the following command:
	>pip install --upgrade pandas
To generate the graphs we presented in this report, please run the following commands in order;
	>./evaluation.sh
	>python3 generate_graphs.py

The evaluation.sh script runs each program and each page replacement algorithm using 100 pages and varying numbers of frames between 1 and 100, and stores the result into a csv file in the csv-files folder. The generate_graphs.py will generate 9 graphs for every algorithm and program combinations, and 1 big graph which combines the comparison graphs of each algorithm. All graphs generated by generate_graphs.py are stored in the project root directory. 


# Graphs of the number of *page faults*, *disk reads*, and *disk writes* for each program and each page replacement algorithm
# Analyze results and describe when one algorithm outperforms the others, and why.
# Customized page replacement algorithm


1. what additional implementations you have added to the original code? How the customized algorithm determines which page to replace?
   
    Our `page_fault_handler_custom`, handles a page fault using the custom policy. 
    
    It can occur if the write permissions were not set or if the page doesnt exist in memory. 

    The page replacement policy for our custom hander is is very similar to LFU cache replacement policy. 

    To achieve this, we implement a new class called `CustomCache`.
    
    In `CustomCache`, we define two hash tables:

    ```
    unordered_map<int, list<Node>::iterator> key_table;
    unordered_map<int, list<Node>> freq_table;
    ```

    The first `freq_table` is indexed by frequency--`freq`. Each index stores a doubly linked list. This linked list stores all caches with frequency `freq`. There are three pieces of information stored in the cache, namely the `key` which is the page number, `val` which is the frame number, and the frequency-- `freq`. 


    The second `key_table` is indexed by the key value `key`, and each index stores the corresponding memory address cached in the linked list in `freq_table`, so that we can use two hash tables to make the time complexity of both `put()` and `get()` operations **O(1 )O(1)**. 
    
    At the same time, it is necessary to record a frequency `minFreq` that is the least used by the current cache, which is for evicting the leased used page operation. 


    * For the `get(key)` operation, we can find the memory address of the linked list cached in `freq_table` in `key_table` through the index `key`. If it does not exist, return -1 directly, otherwise we can get the relevant information of the corresponding cache, so that we can know The `key` value of the cache and the frequency of use can be directly returned to the value corresponding to the key.

        But we noticed that the usage frequency of this cache increases by one after the `get()` operation, so we need to update the location of the cache in the hash table `freq_table`. Knowing the key `key`, value `val`, and usage frequency `freq` of this cache, then the cache should be stored in the linked list under the `freq + 1` index in `freq_table`. So we delete the node corresponding to the cache in **O(1)O(1)** in the current linked list, update the `minFreq` value according to the situation, and then insert it into the head of the linked list under the `freq + 1` index to complete the update. 
    
        We inserted into the head of the linked list when updating. This is actually to ensure that the insertion time cached in the current linked list from the head of the linked list to the end of the linked list is in order, serving the following evict operations.


    * For the `put(key, value)` operation, we first check whether there is a corresponding cache in the `key_table` through the index `key`. If so, the operation is actually equivalent to the `get(key)` operation. The only difference is that we need to put the current cache The `val` in is updated to `value`. If not, it is equivalent to a newly added cache. If the cache has reached capacity, you need to delete the least recently used cache before inserting it.


        Consider insertion first. Since it is newly inserted, the frequency of use of the cache must be 1, so we insert the cached information into the head of the list under index `1` in `freq_table`, and at the same time, update the information of `key_table[key]` and `minFreq = 1`.

    * For the `evict()` operation. Since we maintain `minFreq` in real time, we can know the index with the least frequency of use in `freq_table`. At the same time, because we ensure that the insertion time in the linked list from the head of the linked list to the end of the linked list is in order, the node at the end of the linked list of `freq_table[minFreq]` is the **node with the least frequency of use** and **the earliest insertion time**. We return a pair of ints `<key, val>`. 

2. Difference between LFU cache and our custom cache. 
     
    CustomCache cannot update the cache table upon each memory reference. For example, if a particular page's write permissions were set, memory reference cannot be detected by the `page_fault_handler_custom`.  







